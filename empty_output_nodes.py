"""
ç©ºè¾“å‡ºèŠ‚ç‚¹æ¨¡å—
æ¥æ”¶ä½†ä¸å¤„ç†ä»»ä½•è¾“å…¥ï¼Œå½“ä¸Šçº§èŠ‚ç‚¹æ²¡æœ‰è¿æ¥æ—¶æä¾›é»˜è®¤è¾“å‡º
"""

import torch

class EmptyOutputNode:
    """ç©ºè¾“å‡ºèŠ‚ç‚¹ - æ¥æ”¶ä½†ä¸å¤„ç†ä»»ä½•è¾“å…¥"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "optional": {
                "image_input": ("IMAGE",),
                "latent_input": ("LATENT",),
                "mask_input": ("MASK",),
                "conditioning_input": ("CONDITIONING",),
            },
            "required": {
                "enable_passthrough": ("BOOLEAN", {"default": True}),
                "log_received_data": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "LATENT", "MASK", "CONDITIONING", "STRING")
    RETURN_NAMES = ("image", "latent", "mask", "conditioning", "status")
    FUNCTION = "process_output"
    CATEGORY = "MISLG Tools/Output"
    DESCRIPTION = "ç©ºè¾“å‡ºèŠ‚ç‚¹ï¼Œæ¥æ”¶è¾“å…¥ä½†ä¸å¤„ç†ï¼Œé˜²æ­¢å› æœªè¿æ¥è€ŒæŠ¥é”™"

    def process_output(self, enable_passthrough, log_received_data, image_input=None, latent_input=None, mask_input=None, conditioning_input=None):
        status_parts = []
        
        received_types = []
        if image_input is not None:
            received_types.append(f"å›¾åƒ({image_input.shape})")
        if latent_input is not None:
            received_types.append("æ½œåœ¨ç©ºé—´")
        if mask_input is not None:
            received_types.append(f"æ©ç ({mask_input.shape})")
        if conditioning_input is not None:
            received_types.append("æ¡ä»¶")
        
        if received_types:
            status_parts.append(f"âœ… æ¥æ”¶åˆ°: {', '.join(received_types)}")
        else:
            status_parts.append("âš ï¸ æœªæ¥æ”¶åˆ°ä»»ä½•è¾“å…¥")
        
        if enable_passthrough:
            status_parts.append("ç›´é€šæ¨¡å¼: è¾“å…¥ç›´æ¥è¾“å‡º")
            return (image_input, latent_input, mask_input, conditioning_input, " | ".join(status_parts))
        else:
            status_parts.append("ç›´é€šç¦ç”¨: è¾“å‡ºä¸ºç©º")
            return (None, None, None, None, " | ".join(status_parts))

class UniversalOutputNode:
    """é€šç”¨è¾“å‡ºèŠ‚ç‚¹ - è‡ªåŠ¨é€‚åº”è¿æ¥çŠ¶æ€"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "optional": {
                "any_input": (["IMAGE", "LATENT", "MASK", "CONDITIONING"],),
            },
            "required": {
                "output_type": (["image", "latent", "mask", "auto"], {"default": "auto"}),
                "fallback_width": ("INT", {"default": 512, "min": 64, "max": 4096, "step": 64}),
                "fallback_height": ("INT", {"default": 512, "min": 64, "max": 4096, "step": 64}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "LATENT", "MASK", "STRING")
    RETURN_NAMES = ("image", "latent", "mask", "mode_info")
    FUNCTION = "universal_output"
    CATEGORY = "MISLG Tools/Output"
    DESCRIPTION = "é€šç”¨è¾“å‡ºèŠ‚ç‚¹ï¼Œè‡ªåŠ¨é€‚åº”è¿æ¥çŠ¶æ€"

    def universal_output(self, output_type, fallback_width, fallback_height, any_input=None):
        mode_info = f"è¾“å‡ºç±»å‹: {output_type} | å›é€€å°ºå¯¸: {fallback_width}x{fallback_height}"
        
        if any_input is not None:
            mode_info += " | âœ… ä½¿ç”¨è¾“å…¥æ•°æ®"
            
            if isinstance(any_input, torch.Tensor):
                if len(any_input.shape) == 4 and any_input.shape[-1] in [3, 4]:
                    return (any_input, None, None, f"ğŸ“¤ {mode_info} (ä¼ é€’å›¾åƒ)")
                elif len(any_input.shape) == 2:
                    return (None, None, any_input, f"ğŸ“¤ {mode_info} (ä¼ é€’æ©ç )")
            elif isinstance(any_input, dict) and "samples" in any_input:
                return (None, any_input, None, f"ğŸ“¤ {mode_info} (ä¼ é€’æ½œåœ¨ç©ºé—´)")
        
        mode_info += " | âš ï¸ ä½¿ç”¨å›é€€æ•°æ®"
        
        if output_type == "auto" or output_type == "image":
            image = torch.zeros((1, fallback_height, fallback_width, 3), dtype=torch.float32)
            return (image, None, None, f"ğŸ”„ {mode_info} (å›é€€å›¾åƒ)")
        elif output_type == "latent":
            latent = torch.zeros([1, 4, fallback_height//8, fallback_width//8])
            latent_output = {"samples": latent}
            return (None, latent_output, None, f"ğŸ”„ {mode_info} (å›é€€æ½œåœ¨ç©ºé—´)")
        elif output_type == "mask":
            mask = torch.ones((fallback_height, fallback_width), dtype=torch.float32)
            return (None, None, mask, f"ğŸ”„ {mode_info} (å›é€€æ©ç )")
        else:
            image = torch.zeros((1, fallback_height, fallback_width, 3), dtype=torch.float32)
            return (image, None, None, f"ğŸ”„ {mode_info} (é»˜è®¤å›é€€å›¾åƒ)")

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "EmptyOutputNode": EmptyOutputNode,
    "UniversalOutputNode": UniversalOutputNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "EmptyOutputNode": "ğŸ“¤ ç©ºè¾“å‡ºèŠ‚ç‚¹",
    "UniversalOutputNode": "ğŸ“¤ é€šç”¨è¾“å‡ºèŠ‚ç‚¹",
}