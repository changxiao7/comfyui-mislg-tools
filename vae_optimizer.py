"""
VAE ä¼˜åŒ–èŠ‚ç‚¹æ¨¡å—
ä¼˜åŒ– VAE è§£ç æ€§èƒ½ï¼Œç¡®ä¿è¾“å‡ºèƒ½æ­£å¸¸ä¿å­˜å›¾ç‰‡
"""

import torch
import gc
import numpy as np

class VAEDecoderOptimizer:
    """VAE è§£ç ä¼˜åŒ–å™¨ - ç¡®ä¿æ­£å¸¸ä¿å­˜å›¾ç‰‡"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "samples": ("LATENT", {"tooltip": "è¾“å…¥çš„æ½œåœ¨ç©ºé—´æ•°æ®ï¼Œæ¥è‡ª KSampler æˆ–å…¶ä»–ç”ŸæˆèŠ‚ç‚¹"}),
                "vae": ("VAE", {"tooltip": "VAE æ¨¡å‹ï¼Œç”¨äºè§£ç æ½œåœ¨ç©ºé—´åˆ°å›¾åƒ"}),
                "use_tiled_decoding": ("BOOLEAN", {
                    "default": False, 
                    "tooltip": "å¯ç”¨åˆ†å—è§£ç \n\nâœ… ä¼˜ç‚¹ï¼š\nâ€¢ å‡å°‘å†…å­˜ä½¿ç”¨\nâ€¢ æ”¯æŒå¤§å°ºå¯¸å›¾åƒè§£ç \n\nâŒ ç¼ºç‚¹ï¼š\nâ€¢ å¯èƒ½ç¨å¾®é™ä½é€Ÿåº¦\nâ€¢ æŸäº› VAE æ¨¡å‹ä¸æ”¯æŒ\n\nğŸ“Œ å»ºè®®ï¼š\nâ€¢ å¤§å›¾åƒ(>1024px)æˆ–ä½æ˜¾å­˜æ—¶å¯ç”¨\nâ€¢ å°å›¾åƒå¯å…³é—­ä»¥æé«˜é€Ÿåº¦"
                }),
                "tile_size": ("INT", {
                    "default": 512, 
                    "min": 256, 
                    "max": 2048, 
                    "step": 64,
                    "tooltip": "åˆ†å—è§£ç çš„å—å¤§å°\n\nğŸ’¡ è®¾ç½®å»ºè®®ï¼š\nâ€¢ 4GBæ˜¾å­˜: 256-384\nâ€¢ 6-8GBæ˜¾å­˜: 384-512\nâ€¢ 8-12GBæ˜¾å­˜: 512-768\nâ€¢ 12GB+æ˜¾å­˜: 768-1024\n\nâš ï¸ æ³¨æ„ï¼š\nâ€¢ å€¼è¶Šå°å†…å­˜ä½¿ç”¨è¶Šå°‘ä½†é€Ÿåº¦è¶Šæ…¢\nâ€¢ å€¼è¶Šå¤§é€Ÿåº¦è¶Šå¿«ä½†éœ€è¦æ›´å¤šæ˜¾å­˜"
                }),
                "memory_efficient": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å†…å­˜æ•ˆç‡ä¼˜åŒ–\n\nğŸ”§ åŠŸèƒ½ï¼š\nâ€¢ å¯ç”¨ CUDA åŸºå‡†ä¼˜åŒ–\nâ€¢ è‡ªåŠ¨å†…å­˜ç®¡ç†\nâ€¢ ä¼˜åŒ–è®¡ç®—ç²¾åº¦\n\nâœ… å»ºè®®ï¼š\nâ€¢ é€šå¸¸ä¿æŒå¯ç”¨\nâ€¢ å¦‚æœé‡åˆ°å…¼å®¹æ€§é—®é¢˜å¯å…³é—­"
                }),
                "ensure_float32": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "ç¡®ä¿è¾“å‡ºä¸º float32 æ ¼å¼\n\nğŸ¯ å…³é”®åŠŸèƒ½ï¼š\nâ€¢ å¼ºåˆ¶è¾“å‡ºæ•°æ®ç±»å‹ä¸º torch.float32\nâ€¢ é˜²æ­¢å› æ•°æ®ç±»å‹å¯¼è‡´çš„ä¿å­˜é”™è¯¯\n\nâš ï¸ é‡è¦ï¼š\nâ€¢ å¿…é¡»å¯ç”¨ä»¥ç¡®ä¿èƒ½æ­£å¸¸ä¿å­˜å›¾ç‰‡\nâ€¢ å…³é—­å¯èƒ½å¯¼è‡´æ— æ³•ä¿å­˜è¾“å‡º"
                }),
                "normalize_output": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ ‡å‡†åŒ–è¾“å‡ºèŒƒå›´åˆ° [0, 1]\n\nğŸ“Š åŠŸèƒ½ï¼š\nâ€¢ è‡ªåŠ¨æ£€æµ‹è¾“å…¥å€¼èŒƒå›´\nâ€¢ å°† [-1,1] æˆ–å…¶ä»–èŒƒå›´è½¬æ¢åˆ° [0,1]\nâ€¢ ç¡®ä¿å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…\n\nğŸ’¡ ä½œç”¨ï¼š\nâ€¢ é˜²æ­¢å›¾åƒè¿‡äº®æˆ–è¿‡æš—\nâ€¢ ç¡®ä¿æ˜¾ç¤ºå’Œä¿å­˜æ­£å¸¸"
                }),
                "fix_tensor_shape": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "ä¿®å¤å¼ é‡å½¢çŠ¶\n\nğŸ”„ åŠŸèƒ½ï¼š\nâ€¢ è‡ªåŠ¨è½¬æ¢ BCHW â†’ BHWC æ ¼å¼\nâ€¢ ç¡®ä¿æ­£ç¡®çš„æ‰¹æ¬¡ç»´åº¦\nâ€¢ å¤„ç†ä¸å¸¸è§çš„å¼ é‡å½¢çŠ¶\n\nâœ… å»ºè®®ï¼š\nâ€¢ é€šå¸¸ä¿æŒå¯ç”¨\nâ€¢ å¦‚æœé‡åˆ°å½¢çŠ¶é”™è¯¯å¯å…³é—­è°ƒè¯•"
                }),
                "debug_output": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨è°ƒè¯•è¾“å‡º\n\nğŸ“ åŠŸèƒ½ï¼š\nâ€¢ åœ¨æ§åˆ¶å°æ‰“å°è¯¦ç»†å¤„ç†ä¿¡æ¯\nâ€¢ æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯åœ¨èŠ‚ç‚¹è¾“å‡ºä¸­\nâ€¢ å¸®åŠ©è¯Šæ–­è§£ç é—®é¢˜\n\nğŸ”§ è°ƒè¯•ï¼š\nâ€¢ å¼€å‘æ—¶ä¿æŒå¯ç”¨\nâ€¢ ç”Ÿäº§ç¯å¢ƒå¯å…³é—­å‡å°‘æ—¥å¿—"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "status")
    FUNCTION = "optimized_decode"
    CATEGORY = "MISLG Tools/VAE"
    DESCRIPTION = "ä¼˜åŒ–çš„ VAE è§£ç å™¨ï¼Œç¡®ä¿è¾“å‡ºå…¼å®¹ä¿å­˜èŠ‚ç‚¹\n\nä¸»è¦åŠŸèƒ½ï¼š\nâ€¢ å†…å­˜ä¼˜åŒ–è§£ç \nâ€¢ æ•°æ®ç±»å‹å’Œå½¢çŠ¶ä¿®å¤\nâ€¢ å€¼èŒƒå›´æ ‡å‡†åŒ–\nâ€¢ é”™è¯¯æ¢å¤æœºåˆ¶"

    def optimized_decode(self, samples, vae, use_tiled_decoding, tile_size, memory_efficient,
                        ensure_float32, normalize_output, fix_tensor_shape, debug_output):
        
        status_messages = []
        
        # åˆå§‹çŠ¶æ€ä¿¡æ¯
        if debug_output:
            status_messages.append("ğŸš€ å¼€å§‹ VAE è§£ç ä¼˜åŒ–å¤„ç†")
            print(f"ğŸ”§ VAEè§£ç ä¼˜åŒ–å¯åŠ¨: åˆ†å—={use_tiled_decoding}, åˆ†å—å¤§å°={tile_size}")
        
        try:
            # 1. å†…å­˜ä¼˜åŒ–è®¾ç½®
            if memory_efficient:
                torch.backends.cudnn.benchmark = True
                if debug_output:
                    status_messages.append("âœ… å†…å­˜ä¼˜åŒ–å·²å¯ç”¨")
                    print("âœ… å†…å­˜ä¼˜åŒ–è®¾ç½®å·²åº”ç”¨")
            
            # 2. æ¸…ç† GPU ç¼“å­˜
            if torch.cuda.is_available():
                before_memory = torch.cuda.memory_allocated() / 1024**3 if debug_output else 0
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                if debug_output:
                    after_memory = torch.cuda.memory_allocated() / 1024**3
                    status_messages.append(f"ğŸ§¹ GPUç¼“å­˜å·²æ¸…ç†: {before_memory:.2f}GB â†’ {after_memory:.2f}GB")
                    print(f"ğŸ§¹ GPUç¼“å­˜æ¸…ç†å®Œæˆ")
            
            # 3. æ‰§è¡Œ VAE è§£ç 
            with torch.no_grad():
                if use_tiled_decoding and hasattr(vae, 'decode_tiled'):
                    if debug_output:
                        status_messages.append(f"ğŸ”² ä½¿ç”¨åˆ†å—è§£ç  (åˆ†å—å¤§å°: {tile_size})")
                        print(f"ğŸ”² å¼€å§‹åˆ†å—è§£ç ï¼Œåˆ†å—å¤§å°: {tile_size}")
                    
                    image = vae.decode_tiled(samples['samples'], tile_x=tile_size, tile_y=tile_size)
                    
                    if debug_output:
                        print(f"âœ… åˆ†å—è§£ç å®Œæˆ")
                else:
                    if debug_output:
                        status_messages.append("âš¡ ä½¿ç”¨æ ‡å‡†è§£ç ")
                        print("âš¡ å¼€å§‹æ ‡å‡†è§£ç ")
                    
                    image = vae.decode(samples['samples'])
                    
                    if debug_output:
                        print(f"âœ… æ ‡å‡†è§£ç å®Œæˆ")
            
            # 4. è®°å½•è§£ç åçŠ¶æ€
            if debug_output:
                original_shape = image.shape
                original_dtype = image.dtype
                status_messages.append(f"ğŸ“Š è§£ç å: {original_shape}, {original_dtype}")
                print(f"ğŸ“Š è§£ç å®Œæˆ - å½¢çŠ¶: {original_shape}, ç±»å‹: {original_dtype}")
            
            # 5. ç¡®ä¿è¾“å‡ºå…¼å®¹æ€§
            image = self.ensure_compatible_output(image, ensure_float32, normalize_output, fix_tensor_shape, debug_output)
            
            # 6. è§£ç åæ¸…ç†
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                if debug_output:
                    status_messages.append("ğŸ§¹ è§£ç åç¼“å­˜å·²æ¸…ç†")
                    print("ğŸ§¹ è§£ç åç¼“å­˜æ¸…ç†å®Œæˆ")
            
            # 7. æœ€ç»ˆçŠ¶æ€æŠ¥å‘Š
            if debug_output:
                final_status = f"âœ… è§£ç æˆåŠŸ - è¾“å‡º: {image.shape}, {image.dtype}"
                status_messages.append(final_status)
                print(final_status)
            
        except Exception as e:
            error_msg = f"âŒ VAE è§£ç å¤±è´¥: {str(e)}"
            status_messages.append(error_msg)
            print(f"âŒ VAEè§£ç é”™è¯¯: {str(e)}")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šåˆ›å»ºå…¼å®¹çš„ç©ºç™½å›¾åƒ
            image = self.create_compatible_fallback_image()
            fallback_msg = "ğŸ”„ ä½¿ç”¨å¤‡ç”¨å…¼å®¹å›¾åƒ"
            status_messages.append(fallback_msg)
            print(fallback_msg)
        
        # ç¡®ä¿ status å§‹ç»ˆæœ‰è¾“å‡º
        if not status_messages:
            status_messages.append("â„¹ï¸ è§£ç å®Œæˆï¼ˆè°ƒè¯•è¾“å‡ºå·²ç¦ç”¨ï¼‰")
        
        status = " | ".join(status_messages)
        return (image, status)

    def ensure_compatible_output(self, image, ensure_float32, normalize_output, fix_tensor_shape, debug_output):
        """ç¡®ä¿è¾“å‡ºä¸ ComfyUI ä¿å­˜èŠ‚ç‚¹å®Œå…¨å…¼å®¹"""
        
        if debug_output:
            print(f"ğŸ› ï¸ å¼€å§‹è¾“å‡ºå…¼å®¹æ€§å¤„ç†")
            print(f"ğŸ› ï¸ è¾“å…¥å›¾åƒä¿¡æ¯ - å½¢çŠ¶: {image.shape}, ç±»å‹: {image.dtype}")
        
        # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šå½¢çŠ¶ä¸º (1, 1, H, W, C) æˆ–ç±»ä¼¼çš„ä¸å¸¸è§å½¢çŠ¶
        if len(image.shape) == 5:
            if debug_output:
                print(f"ğŸ”§ æ£€æµ‹åˆ°5ç»´å¼ é‡ï¼Œå°è¯•é™ç»´: {image.shape}")
            # å°è¯•é™ç»´åˆ°4ç»´
            if image.shape[0] == 1 and image.shape[1] == 1:
                image = image.squeeze(0).squeeze(0)
            elif image.shape[0] == 1:
                image = image.squeeze(0)
        
        # å¤„ç† uint8 æ•°æ®ç±»å‹ (|u1)
        if image.dtype == torch.uint8:
            if debug_output:
                print(f"ğŸ”§ æ£€æµ‹åˆ° uint8 æ•°æ®ç±»å‹ï¼Œè½¬æ¢ä¸º float32")
            image = image.float() / 255.0
        
        # ç¡®ä¿æ˜¯ torch.Tensor
        if not isinstance(image, torch.Tensor):
            if debug_output:
                print(f"ğŸ”§ è½¬æ¢éTensorè¾“å…¥ä¸ºTensor")
            image = torch.tensor(image)
        
        # ç¡®ä¿ float32 æ•°æ®ç±»å‹
        if ensure_float32 and image.dtype != torch.float32:
            original_dtype = image.dtype
            image = image.to(torch.float32)
            if debug_output:
                print(f"ğŸ”§ æ•°æ®ç±»å‹è½¬æ¢: {original_dtype} â†’ float32")
        
        # ä¿®å¤å¼ é‡å½¢çŠ¶
        if fix_tensor_shape:
            original_shape = image.shape
            
            # å¤„ç†ç‰¹æ®Šå½¢çŠ¶ (1, 1, H, W, C) æˆ– (1, 1, H, C)
            if len(image.shape) == 4 and image.shape[1] == 1:
                # å½¢çŠ¶ä¸º (B, 1, H, W) æˆ– (B, 1, H, C)
                if image.shape[3] == 3:  # (B, 1, H, 3)
                    image = image.permute(0, 2, 1, 3)  # â†’ (B, H, 1, 3)
                    if debug_output:
                        print(f"ğŸ”§ ç‰¹æ®Šå½¢çŠ¶å¤„ç†: {original_shape} â†’ {image.shape}")
                else:  # (B, 1, H, W)
                    image = image.squeeze(1)  # â†’ (B, H, W)
                    if debug_output:
                        print(f"ğŸ”§ ç§»é™¤å•é€šé“ç»´åº¦: {original_shape} â†’ {image.shape}")
            
            # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            if len(image.shape) == 3:
                image = image.unsqueeze(0)
                if debug_output:
                    print(f"ğŸ”§ æ·»åŠ æ‰¹æ¬¡ç»´åº¦: {original_shape} â†’ {image.shape}")
            
            # è½¬æ¢ BCHW â†’ BHWC
            elif len(image.shape) == 4 and image.shape[1] == 3:
                image = image.permute(0, 2, 3, 1)
                if debug_output:
                    print(f"ğŸ”§ æ ¼å¼è½¬æ¢ BCHW â†’ BHWC: {original_shape} â†’ {image.shape}")
        
        # æ ‡å‡†åŒ–è¾“å‡ºèŒƒå›´
        if normalize_output:
            min_val = torch.min(image).item()
            max_val = torch.max(image).item()
            
            if debug_output:
                print(f"ğŸ“Š å€¼èŒƒå›´æ£€æµ‹: [{min_val:.3f}, {max_val:.3f}]")
            
            if min_val < -0.1 or max_val > 1.1:
                if min_val >= -1.1 and max_val <= 1.1:
                    # [-1, 1] èŒƒå›´è½¬æ¢åˆ° [0, 1]
                    image = (image + 1.0) / 2.0
                    if debug_output:
                        print(f"ğŸ”§ èŒƒå›´è½¬æ¢ [-1,1] â†’ [0,1]")
                else:
                    # å…¶ä»–èŒƒå›´ï¼Œä½¿ç”¨ min-max å½’ä¸€åŒ–
                    image_min = torch.min(image)
                    image_max = torch.max(image)
                    if (image_max - image_min) > 1e-6:
                        image = (image - image_min) / (image_max - image_min)
                        if debug_output:
                            print(f"ğŸ”§ èŒƒå›´å½’ä¸€åŒ– â†’ [0,1]")
            
            # æœ€ç»ˆç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…
            image = torch.clamp(image, 0.0, 1.0)
            if debug_output:
                final_min = torch.min(image).item()
                final_max = torch.max(image).item()
                print(f"âœ… æœ€ç»ˆå€¼èŒƒå›´: [{final_min:.3f}, {final_max:.3f}]")
        
        # æœ€ç»ˆå½¢çŠ¶éªŒè¯
        if len(image.shape) != 4 or image.shape[-1] != 3:
            if debug_output:
                print(f"âš ï¸ æœ€ç»ˆå½¢çŠ¶ä¸æ ‡å‡†: {image.shape}ï¼Œå°è¯•ä¿®å¤")
            image = self.fix_final_shape(image, debug_output)
        
        if debug_output:
            print(f"âœ… è¾“å‡ºå…¼å®¹æ€§å¤„ç†å®Œæˆ - æœ€ç»ˆå½¢çŠ¶: {image.shape}, ç±»å‹: {image.dtype}")
        
        return image

    def fix_final_shape(self, image, debug_output):
        """ä¿®å¤æœ€ç»ˆè¾“å‡ºå½¢çŠ¶ä¸ºæ ‡å‡†çš„ (B, H, W, 3) æ ¼å¼"""
        
        original_shape = image.shape
        
        # å¤„ç† 2D å›¾åƒ (H, W)
        if len(image.shape) == 2:
            image = image.unsqueeze(-1).repeat(1, 1, 3)  # (H, W) â†’ (H, W, 3)
            image = image.unsqueeze(0)  # (H, W, 3) â†’ (1, H, W, 3)
        
        # å¤„ç† 3D å›¾åƒ
        elif len(image.shape) == 3:
            if image.shape[2] == 3:  # (H, W, 3)
                image = image.unsqueeze(0)  # â†’ (1, H, W, 3)
            elif image.shape[0] == 3:  # (3, H, W)
                image = image.permute(1, 2, 0).unsqueeze(0)  # â†’ (1, H, W, 3)
            else:  # (B, H, W) æˆ–å…¶ä»–
                image = image.unsqueeze(-1).repeat(1, 1, 1, 3)  # â†’ (B, H, W, 3)
        
        # å¤„ç† 4D å›¾åƒä½†ä¸æ˜¯æ ‡å‡†æ ¼å¼
        elif len(image.shape) == 4:
            if image.shape[1] == 3:  # (B, 3, H, W)
                image = image.permute(0, 2, 3, 1)  # â†’ (B, H, W, 3)
            elif image.shape[3] != 3:  # (B, H, W, C) ä½† C != 3
                if image.shape[1] == 1 and image.shape[3] == 3:  # (B, 1, W, 3)
                    image = image.squeeze(1)  # â†’ (B, W, 3)
                    # å¯èƒ½éœ€è¦è¿›ä¸€æ­¥å¤„ç†
        
        if debug_output:
            print(f"ğŸ”§ æœ€ç»ˆå½¢çŠ¶ä¿®å¤: {original_shape} â†’ {image.shape}")
        
        return image

    def create_compatible_fallback_image(self):
        """åˆ›å»ºå®Œå…¨å…¼å®¹çš„å¤‡ç”¨å›¾åƒ"""
        return torch.zeros((1, 512, 512, 3), dtype=torch.float32)

class SimpleVAEDecoder:
    """ç®€å• VAE è§£ç å™¨ - æœ€å¤§å…¼å®¹æ€§"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "samples": ("LATENT", {"tooltip": "è¾“å…¥çš„æ½œåœ¨ç©ºé—´æ•°æ®"}),
                "vae": ("VAE", {"tooltip": "VAE æ¨¡å‹ï¼Œç”¨äºè§£ç "}),
                "show_status": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¾ç¤ºå¤„ç†çŠ¶æ€ä¿¡æ¯\n\nğŸ“ åŠŸèƒ½ï¼š\nâ€¢ åœ¨è¾“å‡ºä¸­åŒ…å«çŠ¶æ€ä¿¡æ¯\nâ€¢ å¸®åŠ©äº†è§£è§£ç è¿‡ç¨‹\nâ€¢ ä¸å½±å“å›¾åƒè¾“å‡ºè´¨é‡"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "status")
    FUNCTION = "simple_decode"
    CATEGORY = "MISLG Tools/VAE"
    DESCRIPTION = "ç®€å•çš„ VAE è§£ç å™¨ï¼Œæœ€å¤§å…¼å®¹æ€§\n\nç‰¹ç‚¹ï¼š\nâ€¢ æœ€ç®€å®ç°ï¼Œä¸åšé¢å¤–å¤„ç†\nâ€¢ æœ€å¤§å…¼å®¹æ€§ï¼Œé€‚ç”¨äºå¤§å¤šæ•°æƒ…å†µ\nâ€¢ é€Ÿåº¦æœ€å¿«ï¼Œä½†ç¼ºå°‘ä¼˜åŒ–åŠŸèƒ½"

    def simple_decode(self, samples, vae, show_status):
        status = ""
        
        try:
            if show_status:
                print("ğŸš€ å¼€å§‹ç®€å• VAE è§£ç ")
                status = "å¼€å§‹è§£ç ..."
            
            # ç›´æ¥ä½¿ç”¨ VAE çš„æ ‡å‡†è§£ç 
            image = vae.decode(samples["samples"])
            
            # åŸºæœ¬å…¼å®¹æ€§å¤„ç†
            image = self.ensure_basic_compatibility(image)
            
            if show_status:
                status = f"âœ… è§£ç æˆåŠŸ - è¾“å‡º: {image.shape}, {image.dtype}"
                print(status)
                
        except Exception as e:
            error_msg = f"âŒ è§£ç å¤±è´¥: {str(e)}"
            if show_status:
                status = error_msg
            print(error_msg)
            # è¿”å›å…¼å®¹çš„ç©ºç™½å›¾åƒ
            image = torch.zeros((1, 512, 512, 3), dtype=torch.float32)
        
        return (image, status)

    def ensure_basic_compatibility(self, image):
        """ç¡®ä¿åŸºæœ¬å…¼å®¹æ€§"""
        # å¤„ç† uint8 æ•°æ®ç±»å‹
        if image.dtype == torch.uint8:
            image = image.float() / 255.0
        
        # ç¡®ä¿ float32
        if image.dtype != torch.float32:
            image = image.float()
        
        # ç¡®ä¿æ­£ç¡®å½¢çŠ¶
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        elif len(image.shape) == 4 and image.shape[1] == 3:
            image = image.permute(0, 2, 3, 1)
        
        return image

class ImageDataTypeFix:
    """å›¾åƒæ•°æ®ç±»å‹ä¿®å¤èŠ‚ç‚¹ - ä¸“é—¨è§£å†³æ•°æ®ç±»å‹é”™è¯¯"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {"tooltip": "éœ€è¦ä¿®å¤æ•°æ®ç±»å‹çš„å›¾åƒ"}),
                "force_float32": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¼ºåˆ¶è½¬æ¢ä¸º float32 æ ¼å¼\n\nğŸ¯ åŠŸèƒ½ï¼š\nâ€¢ è§£å†³ uint8 (|u1) æ•°æ®ç±»å‹é”™è¯¯\nâ€¢ ç¡®ä¿ä¸ä¿å­˜èŠ‚ç‚¹å…¼å®¹\nâ€¢ è‡ªåŠ¨å¤„ç†å€¼èŒƒå›´"
                }),
                "fix_problematic_shapes": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "ä¿®å¤é—®é¢˜å½¢çŠ¶\n\nğŸ”„ å¤„ç†å½¢çŠ¶ï¼š\nâ€¢ (1, 1, H, W, C)\nâ€¢ (B, 1, H, W)\nâ€¢ å…¶ä»–ä¸æ ‡å‡†å½¢çŠ¶\nâ€¢ è½¬æ¢ä¸ºæ ‡å‡† (B, H, W, C)"
                }),
                "debug_info": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¾ç¤ºä¿®å¤ä¿¡æ¯\n\nğŸ“ è¾“å‡ºï¼š\nâ€¢ åŸå§‹å½¢çŠ¶å’Œç±»å‹\nâ€¢ ä¿®å¤æ­¥éª¤\nâ€¢ æœ€ç»ˆç»“æœ"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "repair_report")
    FUNCTION = "fix_data_type"
    CATEGORY = "MISLG Tools/VAE"
    DESCRIPTION = "å›¾åƒæ•°æ®ç±»å‹ä¿®å¤èŠ‚ç‚¹\n\nä¸“é—¨è§£å†³ 'Cannot handle this data type' é”™è¯¯"

    def fix_data_type(self, image, force_float32, fix_problematic_shapes, debug_info):
        report_lines = ["ğŸ”§ å›¾åƒæ•°æ®ç±»å‹ä¿®å¤æŠ¥å‘Š:"]
        
        original_shape = image.shape
        original_dtype = image.dtype
        report_lines.append(f"ğŸ“Š åŸå§‹æ•°æ®: {original_shape}, {original_dtype}")
        
        if debug_info:
            print(f"ğŸ”§ å¼€å§‹ä¿®å¤å›¾åƒæ•°æ®ç±»å‹: {original_shape}, {original_dtype}")
        
        # ä¿®å¤æ•°æ®ç±»å‹
        if force_float32:
            if image.dtype == torch.uint8:
                image = image.float() / 255.0
                report_lines.append("âœ… uint8 â†’ float32 (å·²å½’ä¸€åŒ–åˆ° [0,1])")
                if debug_info:
                    print("âœ… ä¿®å¤: uint8 â†’ float32")
            elif image.dtype != torch.float32:
                image = image.float()
                report_lines.append(f"âœ… {original_dtype} â†’ float32")
                if debug_info:
                    print(f"âœ… ä¿®å¤: {original_dtype} â†’ float32")
            else:
                report_lines.append("âœ… å·²æ˜¯ float32 æ ¼å¼")
        
        # ä¿®å¤é—®é¢˜å½¢çŠ¶
        if fix_problematic_shapes:
            fixed_shapes = []
            
            # å¤„ç† 5D å¼ é‡
            if len(image.shape) == 5:
                if image.shape[0] == 1 and image.shape[1] == 1:
                    image = image.squeeze(0).squeeze(0)
                    fixed_shapes.append("ç§»é™¤åŒé‡æ‰¹æ¬¡ç»´åº¦")
                elif image.shape[0] == 1:
                    image = image.squeeze(0)
                    fixed_shapes.append("ç§»é™¤æ‰¹æ¬¡ç»´åº¦")
            
            # å¤„ç† (1, 1, H, W) å½¢çŠ¶
            if len(image.shape) == 4 and image.shape[0] == 1 and image.shape[1] == 1:
                if image.shape[3] == 3:  # (1, 1, H, 3)
                    image = image.permute(0, 2, 1, 3)  # â†’ (1, H, 1, 3)
                    fixed_shapes.append("é‡æ–°æ’åˆ—ç»´åº¦")
                else:
                    image = image.squeeze(1)  # â†’ (1, H, W)
                    fixed_shapes.append("ç§»é™¤å•é€šé“ç»´åº¦")
            
            # ç¡®ä¿æ ‡å‡†å½¢çŠ¶ (B, H, W, 3)
            if len(image.shape) == 3:
                if image.shape[2] == 3:  # (H, W, 3)
                    image = image.unsqueeze(0)  # â†’ (1, H, W, 3)
                    fixed_shapes.append("æ·»åŠ æ‰¹æ¬¡ç»´åº¦")
                else:  # (B, H, W)
                    image = image.unsqueeze(-1).repeat(1, 1, 1, 3)  # â†’ (B, H, W, 3)
                    fixed_shapes.append("æ·»åŠ RGBé€šé“")
            
            elif len(image.shape) == 4 and image.shape[1] == 3:  # (B, 3, H, W)
                image = image.permute(0, 2, 3, 1)  # â†’ (B, H, W, 3)
                fixed_shapes.append("BCHW â†’ BHWC è½¬æ¢")
            
            if fixed_shapes:
                shape_repair = " | ".join(fixed_shapes)
                report_lines.append(f"ğŸ”„ å½¢çŠ¶ä¿®å¤: {shape_repair}")
                if debug_info:
                    print(f"ğŸ”„ å½¢çŠ¶ä¿®å¤: {shape_repair}")
            else:
                report_lines.append("âœ… å½¢çŠ¶æ­£å¸¸")
        
        # æœ€ç»ˆéªŒè¯
        final_shape = image.shape
        final_dtype = image.dtype
        
        report_lines.append(f"ğŸ“Š ä¿®å¤å: {final_shape}, {final_dtype}")
        
        # å…¼å®¹æ€§æ£€æŸ¥
        if len(final_shape) == 4 and final_shape[-1] == 3 and final_dtype == torch.float32:
            report_lines.append("ğŸ‰ ä¿®å¤æˆåŠŸ - å›¾åƒå¯ä»¥æ­£å¸¸ä¿å­˜")
        else:
            report_lines.append("âš ï¸ ä¿®å¤å®Œæˆä½†å½¢çŠ¶å¯èƒ½ä»éœ€è°ƒæ•´")
        
        repair_report = "\n".join(report_lines)
        
        if debug_info:
            print(f"âœ… æ•°æ®ç±»å‹ä¿®å¤å®Œæˆ: {final_shape}, {final_dtype}")
        
        return (image, repair_report)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "VAEDecoderOptimizer": VAEDecoderOptimizer,
    "SimpleVAEDecoder": SimpleVAEDecoder,
    "ImageDataTypeFix": ImageDataTypeFix,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VAEDecoderOptimizer": "âš¡ VAE è§£ç ä¼˜åŒ–",
    "SimpleVAEDecoder": "âš¡ VAE è§£ç å™¨(ç®€å•)",
    "ImageDataTypeFix": "ğŸ”§ å›¾åƒæ•°æ®ç±»å‹ä¿®å¤",
}