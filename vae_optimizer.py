"""
VAE ä¼˜åŒ–èŠ‚ç‚¹æ¨¡å—
ä¼˜åŒ– VAE è§£ç æ€§èƒ½ï¼Œç¡®ä¿è¾“å‡ºèƒ½æ­£å¸¸ä¿å­˜å›¾ç‰‡
"""

import torch
import gc

class VAEDecoderOptimizer:
    """VAE è§£ç ä¼˜åŒ–å™¨ - ç¡®ä¿æ­£å¸¸ä¿å­˜å›¾ç‰‡"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "samples": ("LATENT",),
                "vae": ("VAE",),
                "use_tiled_decoding": ("BOOLEAN", {"default": False}),
                "tile_size": ("INT", {"default": 512, "min": 256, "max": 2048, "step": 64}),
                "memory_efficient": ("BOOLEAN", {"default": True}),
                "ensure_float32": ("BOOLEAN", {"default": True}),
                "normalize_output": ("BOOLEAN", {"default": True}),
                "fix_tensor_shape": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "status")
    FUNCTION = "optimized_decode"
    CATEGORY = "MISLG Tools/VAE"
    DESCRIPTION = "ä¼˜åŒ–çš„ VAE è§£ç å™¨ï¼Œç¡®ä¿è¾“å‡ºå…¼å®¹ä¿å­˜èŠ‚ç‚¹"

    def optimized_decode(self, samples, vae, use_tiled_decoding, tile_size, memory_efficient,
                        ensure_float32, normalize_output, fix_tensor_shape):
        
        status_messages = []
        
        try:
            if memory_efficient:
                torch.backends.cudnn.benchmark = True
                status_messages.append("å†…å­˜ä¼˜åŒ–å·²å¯ç”¨")
            
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                status_messages.append("GPUç¼“å­˜å·²æ¸…ç†")
            
            with torch.no_grad():
                if use_tiled_decoding and hasattr(vae, 'decode_tiled'):
                    image = vae.decode_tiled(samples['samples'], tile_x=tile_size, tile_y=tile_size)
                    status_messages.append(f"ä½¿ç”¨åˆ†å—è§£ç  (åˆ†å—å¤§å°: {tile_size})")
                else:
                    image = vae.decode(samples['samples'])
                    status_messages.append("ä½¿ç”¨æ ‡å‡†è§£ç ")
            
            image = self.ensure_compatible_output(image, ensure_float32, normalize_output, fix_tensor_shape)
            
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                status_messages.append("è§£ç åç¼“å­˜å·²æ¸…ç†")
            
            status_messages.append(f"âœ… è§£ç æˆåŠŸ - è¾“å‡º: {image.shape}, {image.dtype}")
            
        except Exception as e:
            error_msg = f"âŒ VAE è§£ç å¤±è´¥: {str(e)}"
            status_messages.append(error_msg)
            image = torch.zeros((1, 512, 512, 3), dtype=torch.float32)
            status_messages.append("ğŸ”„ ä½¿ç”¨å¤‡ç”¨å…¼å®¹å›¾åƒ")
        
        status = " | ".join(status_messages)
        return (image, status)

    def ensure_compatible_output(self, image, ensure_float32, normalize_output, fix_tensor_shape):
        if not isinstance(image, torch.Tensor):
            image = torch.tensor(image)
        
        if ensure_float32 and image.dtype != torch.float32:
            image = image.to(torch.float32)
        
        if fix_tensor_shape:
            if len(image.shape) == 3:
                image = image.unsqueeze(0)
            elif len(image.shape) == 4:
                if image.shape[1] == 3:
                    image = image.permute(0, 2, 3, 1)
        
        if normalize_output:
            min_val = torch.min(image)
            max_val = torch.max(image)
            
            if min_val < -0.1 or max_val > 1.1:
                if min_val >= -1.1 and max_val <= 1.1:
                    image = (image + 1.0) / 2.0
                else:
                    image_min = torch.min(image)
                    image_max = torch.max(image)
                    if (image_max - image_min) > 1e-6:
                        image = (image - image_min) / (image_max - image_min)
            
            image = torch.clamp(image, 0.0, 1.0)
        
        return image

class SimpleVAEDecoder:
    """ç®€å• VAE è§£ç å™¨ - æœ€å¤§å…¼å®¹æ€§"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "samples": ("LATENT",),
                "vae": ("VAE",),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "simple_decode"
    CATEGORY = "MISLG Tools/VAE"
    DESCRIPTION = "ç®€å•çš„ VAE è§£ç å™¨ï¼Œæœ€å¤§å…¼å®¹æ€§"

    def simple_decode(self, samples, vae):
        return (vae.decode(samples["samples"]),)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "VAEDecoderOptimizer": VAEDecoderOptimizer,
    "SimpleVAEDecoder": SimpleVAEDecoder,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VAEDecoderOptimizer": "âš¡ VAE è§£ç ä¼˜åŒ–",
    "SimpleVAEDecoder": "âš¡ VAE è§£ç å™¨(ç®€å•)",
}