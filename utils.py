"""
å·¥å…·èŠ‚ç‚¹æ¨¡å—
æä¾›å†…å­˜ä¼˜åŒ–ã€å·¥ä½œæµéªŒè¯ç­‰å®ç”¨å·¥å…·
"""

import torch
import gc

class MemoryOptimizer:
    """å†…å­˜ä¼˜åŒ–å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "clear_cuda_cache": ("BOOLEAN", {"default": True}),
                "run_garbage_collect": ("BOOLEAN", {"default": True}),
                "enable_benchmark": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("optimization_status",)
    FUNCTION = "optimize_memory"
    CATEGORY = "MISLG Tools/Utils"
    DESCRIPTION = "ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œæé«˜æ€§èƒ½"

    def optimize_memory(self, clear_cuda_cache, run_garbage_collect, enable_benchmark):
        status = []
        
        if clear_cuda_cache and torch.cuda.is_available():
            before = torch.cuda.memory_allocated() / 1024**3
            torch.cuda.empty_cache()
            after = torch.cuda.memory_allocated() / 1024**3
            status.append(f"GPUç¼“å­˜: {before:.2f}GB -> {after:.2f}GB")
        
        if run_garbage_collect:
            collected = gc.collect()
            status.append(f"åƒåœ¾å›æ”¶: {collected} objects")
        
        if enable_benchmark and torch.cuda.is_available():
            torch.backends.cudnn.benchmark = True
            status.append("CUDAåŸºå‡†ä¼˜åŒ–å·²å¯ç”¨")
        
        optimization_status = " | ".join(status) if status else "æ— æ“ä½œ"
        return (optimization_status,)

class WorkflowValidator:
    """å·¥ä½œæµéªŒè¯å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "optional": {
                "image_input": ("IMAGE",),
                "latent_input": ("LATENT",),
                "mask_input": ("MASK",),
            },
            "required": {
                "validate_connections": ("BOOLEAN", {"default": True}),
                "auto_fix_missing": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "LATENT", "MASK", "STRING")
    RETURN_NAMES = ("image", "latent", "mask", "validation_report")
    FUNCTION = "validate_workflow"
    CATEGORY = "MISLG Tools/Utils"
    DESCRIPTION = "éªŒè¯å·¥ä½œæµè¿æ¥çŠ¶æ€ï¼Œè‡ªåŠ¨ä¿®å¤ç¼ºå¤±è¿æ¥"

    def validate_workflow(self, validate_connections, auto_fix_missing, image_input=None, latent_input=None, mask_input=None):
        report = ["=== å·¥ä½œæµéªŒè¯æŠ¥å‘Š ==="]
        
        inputs_status = []
        if image_input is not None:
            inputs_status.append(f"âœ… å›¾åƒ: {image_input.shape}")
        else:
            inputs_status.append("âŒ å›¾åƒ: æœªè¿æ¥")
        
        if latent_input is not None:
            if isinstance(latent_input, dict) and "samples" in latent_input:
                latent_shape = latent_input["samples"].shape
                inputs_status.append(f"âœ… æ½œåœ¨ç©ºé—´: {latent_shape}")
            else:
                inputs_status.append("âš ï¸ æ½œåœ¨ç©ºé—´: æ ¼å¼å¼‚å¸¸")
        else:
            inputs_status.append("âŒ æ½œåœ¨ç©ºé—´: æœªè¿æ¥")
        
        if mask_input is not None:
            inputs_status.append(f"âœ… æ©ç : {mask_input.shape}")
        else:
            inputs_status.append("âŒ æ©ç : æœªè¿æ¥")
        
        report.extend(inputs_status)
        
        fixed_image = image_input
        fixed_latent = latent_input
        fixed_mask = mask_input
        
        if auto_fix_missing:
            fix_actions = []
            
            if fixed_image is None:
                fixed_image = torch.zeros((1, 512, 512, 3), dtype=torch.float32)
                fix_actions.append("å›¾åƒ â†’ é»˜è®¤é»‘è‰²å›¾åƒ")
            
            if fixed_latent is None:
                fixed_latent = {"samples": torch.zeros([1, 4, 64, 64])}
                fix_actions.append("æ½œåœ¨ç©ºé—´ â†’ é»˜è®¤é›¶å¼ é‡")
            
            if fixed_mask is None:
                fixed_mask = torch.ones((512, 512), dtype=torch.float32)
                fix_actions.append("æ©ç  â†’ é»˜è®¤å…¨ç™½æ©ç ")
            
            if fix_actions:
                report.append("=== è‡ªåŠ¨ä¿®å¤ ===")
                report.extend(fix_actions)
        
        connected_count = sum(1 for x in [image_input, latent_input, mask_input] if x is not None)
        total_count = 3
        
        if connected_count == total_count:
            report.append(f"ğŸ‰ éªŒè¯é€šè¿‡: æ‰€æœ‰ {total_count} ä¸ªè¾“å…¥å·²è¿æ¥")
        elif connected_count > 0:
            report.append(f"âš ï¸ éƒ¨åˆ†è¿æ¥: {connected_count}/{total_count} ä¸ªè¾“å…¥å·²è¿æ¥")
        else:
            report.append("âŒ éªŒè¯å¤±è´¥: æ²¡æœ‰è¾“å…¥è¿æ¥")
        
        validation_report = "\n".join(report)
        return (fixed_image, fixed_latent, fixed_mask, validation_report)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "MemoryOptimizer": MemoryOptimizer,
    "WorkflowValidator": WorkflowValidator,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "MemoryOptimizer": "ğŸ§¹ å†…å­˜ä¼˜åŒ–",
    "WorkflowValidator": "âœ… å·¥ä½œæµéªŒè¯",
}