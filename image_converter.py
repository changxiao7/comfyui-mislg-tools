"""
å›¾åƒè½¬æ¢èŠ‚ç‚¹æ¨¡å—
å°†å›¾åƒè½¬æ¢ä¸ºå„ç§åƒç´ æ ¼å¼ï¼Œæ”¯æŒåƒç´ æ•°æ®åˆ†æ
"""

import torch
import numpy as np

class ImageToPixelInput:
    """å›¾ç‰‡è½¬åƒç´ è¾“å…¥èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "output_format": (["pixel_array", "normalized_tensor", "flat_pixels", "rgb_values"], 
                                {"default": "pixel_array"}),
                "normalize_range": (["0-1", "0-255", "-1 to 1"], {"default": "0-1"}),
                "flatten_pixels": ("BOOLEAN", {"default": False}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("pixel_output", "shape_info")
    FUNCTION = "convert_to_pixels"
    CATEGORY = "MISLG Tools/Image"
    DESCRIPTION = "å°†å›¾åƒè½¬æ¢ä¸ºåƒç´ è¾“å…¥æ ¼å¼"

    def convert_to_pixels(self, images, output_format, normalize_range, flatten_pixels):
        shape_info = f"è¾“å…¥å½¢çŠ¶: {images.shape}, æ ¼å¼: {images.dtype}\n"
        
        if images.dtype != torch.float32:
            images = images.float()
            shape_info += f"è½¬æ¢æ•°æ®ç±»å‹ä¸º float32\n"
        
        processed_images = self.process_images(images, output_format, normalize_range)
        shape_info += f"å¤„ç†åå½¢çŠ¶: {processed_images.shape}\n"
        
        if flatten_pixels and len(processed_images.shape) > 2:
            original_shape = processed_images.shape
            if len(processed_images.shape) == 4:
                processed_images = processed_images.view(processed_images.shape[0], -1, processed_images.shape[3])
            else:
                processed_images = processed_images.view(-1, processed_images.shape[2])
            shape_info += f"å±•å¹³: {original_shape} -> {processed_images.shape}\n"
        
        shape_info += f"è¾“å‡ºæ ¼å¼: {output_format}, èŒƒå›´: {normalize_range}"
        
        return (processed_images, shape_info)

    def process_images(self, images, output_format, normalize_range):
        if normalize_range == "0-255":
            images = images * 255.0
        elif normalize_range == "-1 to 1":
            images = (images * 2.0) - 1.0
        
        if output_format == "normalized_tensor":
            if normalize_range != "0-1":
                images = torch.clamp(images, 0.0, 1.0)
        elif output_format == "flat_pixels":
            if len(images.shape) == 4:
                b, h, w, c = images.shape
                images = images.view(b, h * w, c)
        elif output_format == "rgb_values":
            if images.shape[-1] == 4:
                images = images[..., :3]
        
        return images

class PixelDataAnalyzer:
    """åƒç´ æ•°æ®åˆ†æå™¨"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "pixel_data": ("IMAGE",),
                "analyze_channels": ("BOOLEAN", {"default": True}),
                "show_sample_data": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("statistics", "data_sample", "shape_info")
    FUNCTION = "analyze_pixels"
    CATEGORY = "MISLG Tools/Image"
    DESCRIPTION = "åˆ†æåƒç´ æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯"

    def analyze_pixels(self, pixel_data, analyze_channels, show_sample_data):
        stats = self.calculate_statistics(pixel_data, analyze_channels)
        sample = self.get_data_sample(pixel_data) if show_sample_data else "æ ·æœ¬æ˜¾ç¤ºå·²å…³é—­"
        shape_info = f"æ•°æ®å½¢çŠ¶: {pixel_data.shape}\næ•°æ®ç±»å‹: {pixel_data.dtype}"
        
        return (stats, sample, shape_info)

    def calculate_statistics(self, data, analyze_channels):
        stats = []
        stats.append("=== åƒç´ æ•°æ®ç»Ÿè®¡ ===")
        stats.append(f"å½¢çŠ¶: {data.shape}")
        stats.append(f"æ•°æ®ç±»å‹: {data.dtype}")
        stats.append(f"æœ€å°å€¼: {data.min().item():.6f}")
        stats.append(f"æœ€å¤§å€¼: {data.max().item():.6f}")
        stats.append(f"å‡å€¼: {data.mean().item():.6f}")
        stats.append(f"æ ‡å‡†å·®: {data.std().item():.6f}")
        
        if analyze_channels and len(data.shape) > 1 and data.shape[-1] > 1:
            stats.append("\n=== é€šé“ç»Ÿè®¡ ===")
            for c in range(data.shape[-1]):
                channel_data = data[..., c]
                stats.append(f"é€šé“ {c}: min={channel_data.min().item():.3f}, "
                           f"max={channel_data.max().item():.3f}, "
                           f"mean={channel_data.mean().item():.3f}")
        
        return "\n".join(stats)

    def get_data_sample(self, data):
        try:
            sample_size = min(10, data.numel())
            flat_data = data.flatten()
            sample_indices = torch.linspace(0, flat_data.numel()-1, sample_size).long()
            sample_values = flat_data[sample_indices]
            
            sample_str = "æ ·æœ¬å€¼: " + ", ".join([f"{v:.3f}" for v in sample_values])
            if data.numel() > sample_size:
                sample_str += f" ... (å…± {data.numel()} ä¸ªå…ƒç´ )"
                
            return sample_str
        except:
            return "æ— æ³•ç”Ÿæˆæ ·æœ¬"

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "ImageToPixelInput": ImageToPixelInput,
    "PixelDataAnalyzer": PixelDataAnalyzer,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageToPixelInput": "ğŸ”„ å›¾åƒè½¬åƒç´ ",
    "PixelDataAnalyzer": "ğŸ“Š åƒç´ æ•°æ®åˆ†æ",
}